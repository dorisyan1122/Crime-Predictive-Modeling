---
title: "Predictive Model"
author: "Ziwen Lu, Xuyan Xiu, Doris Yan"
format: html
editor: visual
execute: 
  warning: false
embed-resources: true
---

```{r load packages, echo=FALSE}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(parsnip)
library(baguette)
library(doFuture)
library(doParallel)
library(xgboost)
library(vip)
library(haven)
```

# EDA and Data cleaning

```{r}
# remove STATA attributes
attr(crime_all$viol, "format.stata") <- NULL
attr(crime_all$property, "format.stata") <- NULL

attr(crime_all$viol, "label") <- NULL
attr(crime_all$property, "label") <- NULL
 
str(crime_all)

# generate log(violent crime) and log (property crime)
crime_all_cleaned <- crime_all|>
  # remove NA values in the outcome variables
  filter(!is.na(viol) & !is.na(property))|>
  # generate log values in the outcome variables
  mutate(log_viol=log(viol))|>
  mutate(log_property=log(property))|>
  filter(!(is.infinite(log_viol) | is.infinite(log_property)))|>
  # tot_pop_census and totpop13_17 are both total population estimate. tot_pop_census is from urbanicity dataset, totpop13_17 is from ses dataset. 
  # considering that the ses dataset is ACS 5-year estimate, thus more accurate, we will use totpop13_17 as population estimate
  select(-tot_pop_census)

# explore missing values
missing_values <- colSums(is.na(crime_all_cleaned))

missing_values

missing_values<-as.data.frame(missing_values)

# look at the variables with the most missing values, no variable has over 50% missing values
missing_values_percent<-missing_values|>
  mutate(missing_percent = missing_values/nrow(crime_all_cleaned))|>
  arrange(desc(missing_percent))|>
  top_n(10)
```

# Splitting Data

```{r}
set.seed(904)
crime_split <- initial_split(crime_all_cleaned, prop = 0.8)

crime_train <- training(crime_split)
crime_test <- testing(crime_split)
```

# Cross-validation

```{r}
# set up 5-fold cross validation
set.seed(904)
crime_folds <- vfold_cv(data = crime_train, v = 5)
```

# Violent Crime

## Ridge Regression

### feature and target engineering

```{r}
# create a recipe
ridge_rec <- 
  recipe(log_viol ~ .,
         data = crime_train) |>
  update_role(county,
              year,
              property,
              viol,
              log_property,
              new_role = "id") |>
  step_impute_median(all_predictors())|>
  step_nzv(all_predictors())|>
  step_normalize(all_predictors())
 
# check if feature engineering works to remove variables
ridge_summary<-summary(ridge_rec)

# model
ridge_mod <- 
  linear_reg(penalty = tune(), mixture = 0) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "glmnet")  

ridge_grid<-
  grid_regular(penalty(),
               levels = 20)
# workflow
ridge_wf <- 
  workflow() |>
  add_recipe(recipe = ridge_rec) |>
  add_model(spec = ridge_mod)
```

### choose the best model

```{r}
ridge_resamples <-
  ridge_wf |>
  tune_grid(
    resamples = crime_folds,
    grid = ridge_grid,
    metrics = metric_set(rmse)
    )

ridge_resamples |>
  collect_metrics()

top_ridge_models <-
  ridge_resamples |>
  show_best() |>
  arrange(penalty) 

ridge_resamples|>
  select_best()

ridge_resamples|>
  autoplot()
```

## Lasso

### feature and target engineering

```{r}
lasso_rec <- 
  recipe(log_viol ~ .,
         data = crime_train) |>
  update_role(county,
              year,
              property,
              viol,
              log_property,
              new_role = "id") |>
  step_impute_median(all_predictors())|>
  step_nzv(all_predictors())|>
  step_normalize(all_predictors())

# check if feature engineering works to remove variables
lasso_summary<-summary(lasso_rec)

# create a model
lasso_mod <- 
  linear_reg(penalty = tune(), mixture = 1) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "glmnet")  
 
lasso_grid <-
  grid_regular(penalty(),
               levels = 20)

lasso_wf <-
  workflow() |>
  add_recipe(recipe = lasso_rec) |>
  add_model(spec = lasso_mod)
```

### choose the best model

```{r}
set.seed(904)
lasso_resamples<- 
  lasso_wf|>
  tune_grid(
    resamples = crime_folds,
    grid = lasso_grid,
    metrics = metric_set(rmse)
    )

lasso_resamples |>
  collect_metrics()
  
top_lasso_models <-
  lasso_resamples |>
  show_best() |>
  arrange(penalty) 

lasso_resamples|>
  select_best()

lasso_resamples|>
  autoplot()
```

## Random Forest

### feature and target engineering

```{r}
rf_rec <- 
  recipe(log_viol ~ ., 
         crime_train) |>
   step_impute_median(all_predictors())|>
   update_role(county, 
               year, 
               property, 
               viol, 
               log_property, 
               new_role = "id") 

rf_mod <- 
  rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 200
  ) |>
  set_mode(mode = "regression") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

rf_wf <- 
  workflow() |>
  add_recipe(rf_rec) |>
  add_model(rf_mod)

rf_grid <- grid_regular(
  mtry(range = c(1, 15)),
  min_n(range = c(1, 15)),
  levels = 5
)
```

### choose the best model

```{r}
set.seed(904)
rf_resamples <- 
  tune_grid(
  rf_wf,
  resamples = crime_folds,
  grid = rf_grid)

collect_metrics(rf_resamples)

show_best(rf_resamples, 
          metric = "rmse") 

select_best(rf_resamples)
autoplot(rf_resamples)
```

### Selecting the top 25 important variables

```{r}
rf_final_wf <- 
  rf_wf |> 
  finalize_workflow(select_best(rf_resamples))

rf_fit <- 
  rf_final_wf |>
  fit(data = crime_all_cleaned)

rf_fit|>
  extract_fit_parsnip()|>
  vip(num_features = 20) %>%
  .$data |>
  mutate(
    Importance = Importance / max(Importance),
    Variable = fct_reorder(.x = Importance, .f = Variable)
  ) |>
  ggplot(aes(Importance, Variable)) +
  geom_col()

# every variable ending with 13_17 are SES indicators
# linknoderatio, conNodeRatio and gamma are street connectivity indicators
# tot_pop_ruca and urbanicity are in urbanicity indicators
```

## Linear Regression

### feature and target engineering

```{r}
# build a linear regression recipe
lm_rec <-
  recipe(log_viol ~ ., 
         data = crime_train) |>
   step_impute_median(all_predictors())|>
   update_role(county, year, property, viol, log_property, new_role = "id") 

lm_mod <- linear_reg() |>
  set_mode(mode = "regression") |>
  set_engine(engine = "lm")

lm_wf <- workflow() |>
  add_recipe(lm_rec) |>
  add_model(lm_mod)
```

### choose the best model

```{r}
set.seed(904)
lm_resamples <- lm_wf |>
  fit_resamples(resamples = crime_folds)

lm_resamples |>
  collect_metrics()
```
