---
title: "Predictive Model"
author: "Ziwen Lu, Xuyan Xiu, Doris Yan"
format: html
editor: visual
execute: 
  warning: false
embed-resources: true
---

```{r load packages, echo=FALSE}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(parsnip)
library(baguette)
library(doFuture)
library(doParallel)
library(xgboost)
library(vip)
library(haven)
```

# EDA

```{r}
# remove STATA attributes to make datas into a dataframe
attr(crime_all$viol, "format.stata") <- NULL
attr(crime_all$property, "format.stata") <- NULL

attr(crime_all$viol, "label") <- NULL
attr(crime_all$property, "label") <- NULL
 
str(crime_all)

crime_all_cleaned <- crime_all|>
  mutate(logviol=log(viol))|>
  mutate(logproperty=log(property))|>
  filter(!(is.infinite(logviol) | is.infinite(logproperty)))|>
  filter(!is.na(viol) & !is.na(property))

missing_values <- colSums(is.na(crime_all_cleaned))

missing_values

missing_values<-as.data.frame(missing_values)

# look at the variables with the most missing values
missing_values_percent<-missing_values|>
  mutate(missing_percent = missing_values/nrow(crime_all_cleaned))|>
  arrange(desc(missing_percent))|>
  top_n(10)
```

# Spliting Data

```{r}
set.seed(904)
crime_split <- initial_split(crime_all_cleaned, prop = 0.8)

crime_train <- training(crime_split)
crime_test <- testing(crime_split)
glimpse(crime_train)
```

# Cross-validation

```{r}
set.seed(904)
crime_folds <- vfold_cv(data = crime_train, v = 5)
```

# Ridge Regression

## feature and target engineering

```{r}
# create a recipe
ridge_rec <- 
  recipe(logviol ~ .,
         data = crime_train) |>
  update_role(county,
              year,
              property,
              viol,
              logproperty,
              new_role = "id") |>
  step_impute_median(all_predictors())|>
  step_nzv(all_predictors())|>
  step_normalize(all_predictors())
 
# check if feature engineering works to remove variables
ridge_summary<-summary(ridge_rec)

# model
ridge_mod <- 
  linear_reg(penalty = tune(), mixture = 0) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "glmnet")  

# workflow
ridge_wf <- 
  workflow() |>
  add_recipe(recipe = ridge_rec) |>
  add_model(spec = ridge_mod)
```

## choose the best model

```{r}
set.seed(904)
ridge_resamples<- 
  ridge_wf|>
  tune_grid(
    resamples = crime_folds,
    grid = 20,
    metrics = metric_set(rmse)
    )

ridge_resamples |>
  collect_metrics()

top_ridge_models <-
  ridge_resamples |>
  show_best() |>
  arrange(penalty) 

ridge_resamples|>
  select_best()

ridge_resamples|>
  autoplot()
```

# Lasso

## feature and target engineering

```{r}
lasso_rec <- 
  recipe(logviol ~ .,
         data = crime_train) |>
  update_role(county,
              year,
              property,
              viol,
              logproperty,
              new_role = "id") |>
  step_impute_median(all_predictors())|>
  step_nzv(all_predictors())|>
  step_normalize(all_predictors())

# check if feature engineering works to remove variables
lasso_summary<-summary(lasso_rec)

# create a model
lasso_mod <- 
  linear_reg(penalty = tune(), mixture = 1) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "glmnet")  
 
lasso_wf <-
  workflow() |>
  add_recipe(recipe = lasso_rec) |>
  add_model(spec = lasso_mod)
```

## choose the best model

```{r}
set.seed(904)
lasso_resamples<- 
  lasso_wf|>
  tune_grid(
    resamples = crime_folds,
    grid = 20,
    metrics = metric_set(rsq)
    )

lasso_resamples |>
  collect_metrics()
  
top_lasso_models <-
  lasso_resamples |>
  show_best() |>
  arrange(penalty) 

lasso_resamples|>
  select_best()

lasso_resamples|>
  autoplot()
```

# Random Forest

## feature and target engineering

```{r}
rf_rec <- 
  recipe(viol ~ ., crime_train) |>
   step_impute_median(all_predictors())|>
   update_role(county, 
              year, 
              new_role = "id")

rf_rec_summary<-summary(rf_rec)

rf_mod <- 
  rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 100
  ) |>
  set_mode(mode = "regression") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

rf_wf <- workflow() |>
  add_recipe(rf_rec) |>
  add_model(rf_mod)

rf_grid <- grid_regular(
  mtry(range = c(1, 15)),
  min_n(range = c(1, 15)),
  levels = 5
)
```

## choose the best model

```{r}
set.seed(904)
rf_resamples <- tune_grid(
  rf_wf,
  resamples = crime_folds,
  grid = rf_grid
)

collect_metrics(rf_resamples)

show_best(rf_resamples, 
          metric = "rmse") 

select_best(rf_resamples)
autoplot(rf_resamples)
```

## variable importance

```{r}
# Selecting the top 25 important variables
rf_fit <- rf_final_wf |>
  fit(data = crime_train)

rf_fit|>
  extract_fit_parsnip()|>
  vip(num_features = 20) %>%
  .$data |>
  mutate(
    Importance = Importance / max(Importance),
    Variable = fct_reorder(.x = Importance, .f = Variable)
  ) |>
  ggplot(aes(Importance, Variable)) +
  geom_col()
```
