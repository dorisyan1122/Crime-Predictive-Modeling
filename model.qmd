---
title: "Predictive Model"
author: "Ziwen Lu, Xuyan Xiu, Doris Yan"
format: html
editor: visual
execute: 
  warning: false
embed-resources: true
---
```{r load packages, echo=FALSE}
library(tidyverse)
library(tidymodels)
library(ggplot2)
```

# Spliting Data

```{r}
set.seed(904)
crime_split <- initial_split(crime_all_cleaned, prop = 0.8)

crime_train <- training(crime_split)
crime_test <- testing(crime_split)
```

# Cross-validation

```{r}
set.seed(904)
crime_folds <- vfold_cv(data = crime_train, v = 5)
```

# Ridge Regression

## feature and target engineering

```{r}
fit_ridge <- function(data, penalty) {
  
  # create a recipe
  ridge_rec <- 
    recipe(viol ~ ., data = crime_train) |>
    step_impute_median(all_predictors())|>
    update_role(county, 
              year, 
              new_role = "id") |>
    step_normalize(all_predictors())
  
  # model
  ridge_mod <- 
    linear_reg(penalty = penalty, mixture = 0) |>
    set_mode(mode = "regression") |>
    set_engine(engine = "glmnet")  
  
  ridge_wf <- workflow() |>
    add_recipe(recipe = ridge_rec) |>
    add_model(spec = ridge_mod)
  
  ridge_wf |>
    fit(data = crime_train) |>
    extract_fit_parsnip() |>
    tidy() |>
    mutate(penalty = penalty)

}
```


```{r}
ridge_fit <- seq(0, 50, 1) |>
  map_dfr(.f = ~ fit_ridge(crime_train, .x))
```


```{r}
ggplot() +
  geom_line(
    data = filter(ridge_fit, term != "(Intercept)"),
    mapping = aes(penalty, estimate, group = term),
    alpha = 0.4
  ) +
  geom_point(
    data = filter(ridge_fit, term != "(Intercept)", penalty == 0),
    mapping = aes(penalty, estimate),
    color = "red"
  )
```

## ridge new
```{r}
# create a recipe
ridge_rec <- 
  recipe(viol ~ ., data = crime_train) |>
  update_role(county, 
              year, 
              new_role = "id") |>
  step_impute_mean(all_predictors())|>
  step_normalize(all_predictors()) |>
  step_dummy(all_nominal_predictors())

# tuning grid
ridge_grid <- 
  grid_regular(penalty(range = c(0.001, 10)), levels = 20)

# model
ridge_mod <- 
  linear_reg(penalty = penalty, 
             mixture = 0) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "glmnet") |>
  set_args(penalty = tune())

# workflow
ridge_wf <- workflow() |>
  add_recipe(recipe = ridge_rec) |>
  add_model(spec = ridge_mod)
```

```{r}
tune_results <- tune_grid(
  object = ridge_wf,
  resamples = crime_folds,
  grid = ridge_grid,
  metrics = metric_set(rmse)
)

best_penalty <- select_best(tune_results, "rmse")

final_ridge_mod <- linear_reg(penalty = best_penalty$penalty, mixture = 0) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

final_ridge_wf <- workflow() %>%
  add_recipe(ridge_rec) %>%
  add_model(final_ridge_mod)

final_fit <- final_ridge_wf %>%
  fit(data = crime_train)

```

## choose the best model

```{r}
set.seed(904)
ridge_resamples<- 
  ridge_wf|>
  tune_grid(
    resamples = crime_folds,
    grid = ridge_grid,
    metrics = metric_set(rmse)
    )

collect_metrics(ridge_resamples)
  
top_ridge_models <-
  ridge_resamples |>
  show_best() |>
  arrange(penalty) 

ridge_resamples|>
  select_best()
```

# Lasso

## feature and target engineering

```{r}
lasso_rec <-
    recipe(viol ~ ., data = crime_train) |>
    step_impute_median(all_predictors())|>
    update_role(county, 
              year, 
              new_role = "id") |>
    step_normalize(all_predictors()) 

# check if feature engineering works to remove variables
lasso_summary<-summary(lasso_rec)

# create a model
lasso_mod <- 
  linear_reg(penalty = tune(), mixture = 1) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "glmnet")  

lasso_grid <-
  tibble(penalty = 10^seq(-4, -1, length.out = 30))
 
lasso_wf <-
  workflow() |>
  add_recipe(recipe = lasso_rec) |>
  add_model(spec = lasso_mod)
```

## choose the best model

```{r}
set.seed(904)
lasso_resamples<- 
  lasso_wf|>
  tune_grid(
    resamples = crime_folds,
    grid = lasso_grid,
    metrics = metric_set(rmse)
    )

lasso_resamples |>
  collect_metrics()
  
top_lasso_models <-
  lasso_resamples |>
  show_best() |>
  arrange(penalty) 

lasso_resamples|>
  select_best()

lasso_resamples|>
  autoplot()
```

# Random Forest

## feature and target engineering

```{r}
rf_rec <- 
  recipe(viol ~ ., crime_train) |>
   step_impute_median(all_predictors())|>
   update_role(county, 
              year, 
              new_role = "id")

rf_rec_summary<-summary(rf_rec)

rf_mod <- 
  rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 100
  ) |>
  set_mode(mode = "regression") |>
  set_engine(
    engine = "ranger", 
    importance = "impurity",
    num.threads = 4
  )

rf_wf <- workflow() |>
  add_recipe(rf_rec) |>
  add_model(rf_mod)

rf_grid <- grid_regular(
  mtry(range = c(1, 15)),
  min_n(range = c(1, 15)),
  levels = 5
)
```

## choose the best model

```{r}
set.seed(904)
rf_resamples <- tune_grid(
  rf_wf,
  resamples = crime_folds,
  grid = rf_grid
)

collect_metrics(rf_resamples)

show_best(rf_resamples, 
          metric = "rmse") 

select_best(rf_resamples)
autoplot(rf_resamples)
```

## variable importance

```{r}
# Selecting the top 25 important variables
rf_fit <- rf_final_wf |>
  fit(data = crime_train)

rf_fit|>
  extract_fit_parsnip()|>
  vip(num_features = 20) %>%
  .$data |>
  mutate(
    Importance = Importance / max(Importance),
    Variable = fct_reorder(.x = Importance, .f = Variable)
  ) |>
  ggplot(aes(Importance, Variable)) +
  geom_col()
```